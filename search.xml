<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Mysql学习笔记]]></title>
    <url>%2F2018%2F12%2F15%2FMysql%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[结构 连接池组件 管理服务和工具组件 SQL接口组件 查询优化器组件 优化器组件 缓存组件 插件式存储引擎（是mysql区别于其他db的重要特性，不同引擎有不同特点，开发者可以根据引擎接口编写主键的存储引擎或者修改已有引擎的源码来实现自己的需求） 物理文件 InnoDB基础 划重点：很多人用 基本介绍 支持事务（OLTP（联机事务处理过程）应用常见需求） 支持行锁（提高单表并发能力） 支持MVCC（实现读写并发和基于该特性实现的隔离级别） 支持外键（分布式部署下不建议使用） 高级功能 插入缓冲 二次写：doubl ewrite：看不懂，应该是个保障服务器宕机后的数据一致性机制，skip it！ 自适应哈希索引 哈希查找很快O(1) innodb是否建立hash表由系统决定，不能人为干预，所以叫自适应 通过buffer_pool的B+树构造，且按需建立，所以建立速度很快 提高读写数据（聚集索引提升2倍，普通索引5倍） 预读 其他描述 表空间：ibd文件，由InnoDB管理 聚集索引：表的存储按聚集索引的顺序存放 使用 TCP方式：mysql -h 192.168.0.1 -u root -p root mysql通过持有一张权限表来判断TCP权限：user表 InnoDB体系架构模型 拥有多个内存块 -&gt; 内存池，负责： 维护所有mysql线程/进程需要访问的数据资源 缓存磁盘数据，方便快速读取，缓冲写操作，并通过后续的脏页刷盘达到顺序写的效果提高效率 存储各种过日志：redo、undo、slow、query buffer pool redo log buffer additional memory pool 后台线程，负责： 根据LRU原则从磁盘读取并刷新内存池数据 将写数据刷新到磁盘保证ACID特性 7个线程： 4个IO线程(可配置，默认4) insert buffer thread log thread read thread write thread 1个master线程 1个锁监控线程 1个错误监控线程 工作方式 以页(16K)为单位将数据从磁盘读取到buffer pool，线程按LRU算法操作 写操作时，先修改在缓冲池中的页并将操作日志存放到redolog中进行持久化，成为脏页后按一定的频率进行刷盘，如果脏页刷盘失败如服务器挂掉，则重启后从redolog进行恢复 内存构成详细 buffer pool innodb_buffer_pool_size指定缓冲池大小 show engine innodb status查看buffer pool的使用情况 buffer pool size：总大小 free buffers：可用大小 database pages：已用大小 modified db pages：脏页大小 存放内容 索引页（核心） 数据页（核心） undo页 插入缓冲：在单条记录插入时， 聚集索引插入顺序读取，无效率问题 普通索引无顺序，且可能会有多个，插入效率降低（B+树的特性） 判断普通索引页是否在缓冲区，如果在直接更新，如果不在存放在插入缓冲区，通过master thread进行merge操作，这样可以将多个普通索引插入操作合并到一个merge操作中，大大提高普通索引的插入和修改性能，某种意义上也是脏页的一种，所以如果考虑服务器宕机的情况，就会需要很长时间的恢复操作。引申一点：在单机环境下总是要考虑服务器是不可靠的是会宕机的，而在分布式环境下，除了要考虑单机宕机还要考虑网络传输是不可靠的，甚至是不安全的（信息截取），从这两个方面引申出来的就是目前互联网上各种系统、中间件如此复杂的最大原因之一，比如：单点问题、高可用、主从、CAP、分布式事务、一致性协议、HTTPS等等 自适应hash索引 锁信息 数据字典 从上述可以看到没有redolog，那么放哪里呢？ 日志缓冲log_buffer：用于redolog缓冲，落盘到redolog之后可以重用，所以无需设置太大 额外内存：理解为用于管理buffer pool的一些元数据 线程详解 master thread核心工作线程 小循环操作（每秒） 脏页刷盘 redolog日志刷盘（由于write_ahead机制log_buffer中的数据从事务开始就写，但是即使事务没有提交，也会进行这一步的刷盘操作，提高大事务的commit效率） 合并插入缓冲（将多条写语句merge为一条） 大循环操作（每10秒） 除了上述三个动作也会做，还负责： 删除undo页（在MVCC机制下，只要当undo的数据版本没有在任何一个事务中作为快照返回才能进行删除操作） 生成checkpoint 高并发下的缺点 没有跟上硬件（SSD）的发展速度导致它这种模式慢 文件 分类如下： 参数文件 kv结构，保存mysql所有配置数据 show varables like &#39;%%&#39;查看全部数据 日志文件 errorlog（用于dba错误排查） slowlog（用于sql优化） querylog（好像没什么卵用） binlog（记录所有写操作，用于本机恢复和replica同步） socket文件 pid文件 表结构文件（mysql系统对表结构信息的存储） 存储引擎文件（innodb对表结构信息的存储） 表空间文件（存储表数据） 重做日志文件： 存在多份，记录事务日志，空间可以复用，脏页刷盘后可以被覆写。 作用是如果服务器挂掉，服务器重启会读取redolog进行事务数据恢复保证ACID特性不被破坏。 和binlog的区别： binlog记录mysql所有引擎的动作 binlog记录事务具体操作，redolog记录页的变更情况（这里和脏页建立关联，从而配合第一条的刷盘覆写） binlog再事务提交前才进行记录，redolog在事务开始过程中不断写入（当然考虑日志缓冲，但是配合master thread的未提交刷盘动作，说是不断写入也是正确的）顺便说下binlog的三种记录模式：row-&gt;记录每一行的修改操作，statement-&gt;记录每一条修改操作，mix-&gt;根据结果选择上述其中一种，比如删全表100条，row模式记录100条日志，statement记录一条即可，mix的选择判断来源于expain的rows信息 表 数据的存放和组织组成结构：tablespace -&gt; segment -&gt; extent -&gt; page -&gt; row tablespace，存放内容如下：（其他信息存放在共享表空间，和额外内存的关系???） 数据 索引 插入缓冲 segment： 数据段：innodb数据由聚集索引组织，所以数据段就是B+树的叶子节点 索引段：B+树的非叶子节点 回滚段 extent：连续64个页组成 page：innodb磁盘管理的最小单位，16K 根据存放内容划分的不同页类型： 数据页 undo页 系统页 事务数据页 插入缓冲位图页 插入缓冲空闲列表页 未压缩的二进制大对象页 压缩的二进制大对象页 页的存放结构 file header 页所属空间 表空间页的偏移量 上下页引用（B+树的叶节点的双向关联） 页最后修改的LSN（log sequence number） 页类型 page header infimun + supremum records user records free space page directory file trailer感觉和java的对象结构和类结构很像，顺便回忆一下java对象结构：Object header(markword(hashcode + gc age + flag + lock status) + klass pointer + array size)+ object body + padding，类结构：cafe babe + sub version + main version + constants pool size + constant pool + access flag + field + method + code + … row：innodb存放数据的单位，每一页最多存储8千行 skip数据完整性约束部分，因为分布式数据库一般禁止使用外键、视图、存储过程，甚至唯一键都希望能在程序中进行保证而不是通过数据库。 skip分区表，不知道是什么鬼（在学习知识的过程中，进行信息筛选也是非常重要的） 索引 lielaliela终于来了~ 概述 索引用于提高查询效率，但是减低写效率，是一种均衡的考虑。tip：所有技术选型其实都是折衷和均衡的艺术 查询算法三板斧 哈希：O(1)，可惜不支持顺序，但是使用DB的应用顺序查询是非常重要的脱离实际业务的技术都是耍流氓，所以mysql很少用到哈希，唯一用到地方就是上述的自适应哈希索引。 顺序：O(n)，属于鸡肋，弃之。 二叉树：O(logn)，属于顺序和查询皆可的方式，原生二叉树查找在DB大数据量的层面下显得太书生气，一个是树高太高导致IO次数太多，一个是节点存储数据太少，导致无法利用磁盘预读，于是进行改造后形成B+树，每个非叶子节点存储一页数据（16K），比如一个自增主键索引用16位的long类型，那么能存储1000个子节点，子节点同理，也就是到第三阶，就能存储几亿级别的数据量，另外B+树叶子节点之间通过双向连接，在顺序查询的效率上更加高效。另外根据上述的索引构成，B+树索引并不能找到具体数据所在行，而只能找到行所在页，所以mysql通过将页读入内存再进行查找才能得到数据。 一般来说，应用的数据的表都不会多的离谱，所以一般2-3阶B+树就能满足所有的需求，也就是IO2-3尺就能拿到数据所在的页，根据普通SATA盘的寻道时间10ms左右，所以20-30ms就能查到数据相应数据，当然具体来说需要根据使用的索引类型和查询范围来确定。 聚集索引 如上述所言，innodb通过聚集索引的顺序来进行数据存储，那么以聚集索引构建的B+树的叶子节点也就是实际磁盘中的数据存储顺序，实际上其实就是这样：聚集索引的叶子节点直接存储行数据，这个特性决定了： 数据是索引的一部分 只能以一颗B+树顺序进行构建，所以只能有一个聚集索引 普通索引的叶子节点存放聚集索引的值，然后通过二次查找进行数据获取 因为能在叶子节点上直接找到数据，所以通过聚集索引查询效率更高这里有个例外情况：如果我们查找的数据就是聚集索引所在的字段，那么通过普通查询获取到了聚集索引之后就无需进行二次查找，直接返回，再考虑到行数据所占空间肯定比聚集索引字段占用空间大，于是单位页下后者能存储的数据量更多，所以定位的速度更快，这就是覆盖索引的原理 聚集索引决定了数据的存储顺序，这里要注意的是并不是物理顺序，而是逻辑顺序，因为如果是物理顺序，由于行数据所占空间大小的不确定性，要维护这个物理顺序是非常困难的，实际它是通过在页间用双向链表，页内也是双向链表的方式进行数据组织。 非聚集索引：也叫二级索引、普通索引、辅助索引 不决定数据顺序，所以可以有多个普通索引 也是由于不决定数据顺序，所以进行的是随机读，确实导致读取效率是偏低的，但是通过预读和缓冲区等技术减低了相应成本。 联合索引 联合索引也只建立一颗B+树 根据索引组合的顺序如a+b+c建立，整体视角下，a是有序的，在a确定之后，b才是有序的，而整体视图下b本身是无序的，如果后面还有依次类推，于是有下面机制 头部匹配 配合sql索引优化器，如果建立了abc联合索引，那么所有组合： a（可以） b（不可以） c（不可以） ab（可以） ba（可以） ac（可以） ca（可以） bc（不可以） cb（不可以） abc（可以） acb（可以） bac（可以） bca（可以） cab（可以） cba（可以） 索引管理 索引的增删：创建新表（新索引） -&gt; 导入数据 -&gt; 删除原表 -&gt;命名新表为原表 快速创建方式：只针对普通索引，聚集索引还是按上述方式处理：表加上读锁 -&gt; 更新内部视图 -&gt; 标记普通索引空间为可用 -&gt; 删除视图上的定义。 show index from table查看索引信息，其中有个关键信息：cardinality(区分度)（distinct(index_field)/table_count）用于描述该索引下区分度，也就是说cardinality=1意味着唯一索引，如果很小，就应该是否应该建立索引。该值是并不会在实时更新，是一个概值，用于索引优化器进行判断是否需要走索引或者是走扫描方式。 什么时候考虑建普通索引： 高区分度（无区分度比如不建,比如boolean值建索引） 少量获取（虽然区分度高但是大量获取，比如获取time &lt; now） 针对上面两种情况，我们是不建议建索引吗，但是即便你建立了索引，优化器也可能不会走 其他概念了解 顺序读：虽然上面提高聚集索引的数据也只是逻辑顺序并不是磁盘顺序，本质上也是随机读，但是从整体上来看是存在一定顺序，比如在区上是连续的64个页。 随机读：需要磁头不断移动，SATA盘瓶颈正是在于寻址时间长，所以效率低（SSD如何?）。 预读：一次IO请求获取多个页数据放在buffer pool，这种机制下，聚集索引就更有优势，有可能一次IO就能完成数据查找，而对随机读来说，获取的数据量越多，数据可能存在的概率也越大，减少随机读的次数的概率也越大。 锁 如上所述，所有架构选型都是均衡的艺术：数据库的选型就是性能（并发）和一致性的均衡。保证一致性的方式：锁 DB区分于文件系统的特性 完整性约束 锁 事务 innodb的锁 共享锁：读读并发，读写互斥，写写互斥 独占锁：独占！ 意向锁：表级别的锁，目的是为了在事务中揭示下一行要被请求的锁的类型（看不懂(┬＿┬)） 三张表 innodb_trx 事务ID 当前事务状态 事务开始时间（可以用于快照的版本确定） 等待目标事务的锁ID，配合事务状态为lock wait 事务等待开始时间 事务权重（死锁时权重最小的回滚） 线程ID 事务运行的sql innodb_locks 锁ID 事务ID 锁模式 锁类型（表锁/行锁） 锁住的表 锁住的索引（通过锁住聚集索引实现的行锁） 表空间ID 锁住的页数量（行锁才有意义） 锁住的行数量（行锁才有意义） 锁住的行的主键值（多行如何设置?） innodb_waits 申请锁资源的事务ID 申请的锁ID 阻塞的事务ID 阻塞的锁ID 快照读 通过MVCC的思想实现读写并发（共享锁的并发能力还不够），通过读取快照版本数据实现快照版本通过undo实现，但与其说是undo实现，倒不如说是innodb的undo机制正好用于实现快照，从而可以在不带来额外成本的情况下实现MVCC机制 在不同事务隔离级别下的不同表现 RC：读取最新快照信息 RR：读取开始时的最老快照信息，需要注意事务开始时间和数据读取时间不一样，而这里的开始时间指的是后者 innodb的select操作默认都是快照读，同时也支持读加锁（当前读） select … for update：所读记录加X锁，但是依然能被快照读 select … lock in share mode：所读记录加S锁，显然能被快照读 上述两种读取方式需要在事务中，当事务结束释放锁（类似于Lock） 其他锁 自增主键锁：表锁 外键和锁：skip！ 锁算法 record lock：行锁 gap lock：间隙锁 next-key lcok：临键锁 = record lock + gap lock select where id &lt; 6 lock in share mode：那么insert id=3阻塞，insert id=10成功 锁解决事务带来的问题 更新丢失：两个事务同时读取并根据记录值进行修改操作，用户有100块钱，T1事务读取到100，T2也读取到100，两者同时花钱100得到-100，如果有非负约束得到0，而用户花出去200，则显然是错误的，处理方法：串行执行（加锁）。 脏读：事务a读取到事务b未提交的数据，违反隔离性原则。RC级别下就可以解决，方式是：快照读，因为快照读的版本是通过undo段实现的，如果事务未提交，undo段会回滚并删除。 不可重复读：一个事务两次读取数据不一致，这里的数据分两种，一个单条数据被update后的不一致，一个是数据被insert或者delete带来的不一致，一般来说前者叫不可重复读，由RR级别解决，后者叫幻读由Serialize级别解决，但是innodb环境下，两者都称为不可重复读，所以RR就需要将两者全部解决，方式是：通过最旧快照读 + 临键锁解决，最旧快照读保证update不可见，临键锁保证插入和删除阻塞。 阻塞 一个事务中需要等待另外一个事务中的锁释放，通过posix thread模型中的mutex_enter函数实现，释放由mutex_exit实现，这里考虑synchronized的monitor_enter和moniter_exit是一样的实现。 死锁：拉到最上面的线程那块，介绍了多种线程，其中有一种就是锁监控线程，负责查看死锁问题并告知用户，大部分情况下，数据库可以自己解决死锁：通过事务回滚即可（还记得上面的事务权重吗） 事务 事务的ACID特性 如何保证已提交事务的ACID log_buffer + redolog实现 事务开始时就写log_buffer并记录LSN 事务提交时将log_buffer的记录写入redo（未提交也写入，见master thread部分） redolog落盘 上述两步称为wrtie-ahead logging机制 如何保证未提交事务的ACID undo段 事务开始时写入undo 存放在共享表空间的特殊segment中（redo放在文件redolog中） 存放内存： 对于insert，存放insert记录的ID（回滚时直接根据ID记性delete） 对于delete，存放整条原记录（回滚时直接insert） 对于update，存放整条原记录（回滚时直接udpate） 总结 整片下来花了五个小时，基本是对之前innodb相关知识的回顾和串联，当然也理清了一些思路，收货很大，书如下：]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>InnoDB</tag>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty学习笔记]]></title>
    <url>%2F2018%2F12%2F14%2FNetty%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[IO基础BIO 没有缓冲区，通过InputStream/OutputStream直接从用户空间到内核空间（为什么这样效率很低?） 同步阻塞IO，导致线程也被阻塞 NIO Buffer 是一块可写入和读取的内存块，包装后提供了一组方法进行内存块的操作和访问 基本用法 capacity：缓冲区总容量 position：游标位置（写操作下，游标和limit一样一直增加，rewind时，游标复位，limit不变，flip时，游标复位并将limit设置成之前position的值） limit：缓冲区已用大小 flip()：- 当向buffer写入数据时，buffer会记录下写了多少数据。一旦要读取数据需要通过flip()方法将Buffer从写模式切换到读模式。在读模式下，可以读取之前写入到buffer的所有数据。 clear()：一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。有两种方式能清空缓冲区：调用clear()或compact()方法。clear()方法会清空整个缓冲区。compact()方法只会清除已经读过的数据12345678910111213RandomAccessFile aFile = new RandomAccessFile(&quot;nio-data.txt&quot;, &quot;rw&quot;);FileChannel inChannel = aFile.getChannel();ByteBuffer buf = ByteBuffer.allocate(48); // 生成48字节大小的缓冲区int bytesRead = inChannel.read(buf); // 读取数据到缓冲区while (bytesRead != -1) &#123; buf.flip(); // 准备从缓冲区读取数据 while(buf.hasRemaining())&#123; System.out.print((char) buf.get()); // 每次读取1个字节 &#125; buf.clear(); // 清空用于再次读取 bytesRead = inChannel.read(buf);&#125;aFile.close(); 关于HeapByteBuffer和DirectByteBuffer的几个疑问释疑 DirectByteBuffer是否是内核空间? DirectByteBuffer毫无疑问属于堆外内存，但是依然属于操作系统体系中的用户空间，它通过glibc的ptmalloc函数分配的内存。 DirectByteBuffer为什么能提高效率? DirectByteBuffer能减少一次拷贝,也就是说即使直接用HeapByteBuffer进行IO的时候也会默认创建一个DirectByteBuffer进行中转 为什么HeapByteBuffer不能直接写到内核空间而需要先拷贝到DirectByteBuffer再到内核空间? 因为内核空间的ReadFile（FileInputStream与FileChannel对比 ）方法要求必须连续的内存，且使用期间该内存不得被操作。 而在jvm-heap上这两点都不能满足 HeapByteBuffer分配出来的内存块处于jvm-heap上，在GC后（带有整理过程的算法如CMS），内存地址会改变 HeapByteBuffer持有的byte[]数组在jvm规范下并不要求内存连续 而c-heap都能满足 GC管不着，由操作系统进行内存空间管理 glibc.ptmalloc分配的内存保证连续 能直接对DirectByteBuffer进行业务操作吗? 不能，如果需要对数据进行业务操作（编解码、解析、过滤），还是需要拷贝的jvm-heap。 综上所述：和我之前想法也是一致的，与其说DirectByteBuffer节省了内存拷贝，倒不如说是因为HeapByteBuffer要多一次拷贝，所以DirectByteBuffer要快一些。 所以netty使用堆外内存进行优化是这样的： 如果是用于RPC服务开发：利用堆外内存实现数据发送时的零拷贝，另外通过CompositeByteBuf的bytep[]组装功能实现零拷贝 如果是用于服务转接开发：利用堆外内存实现读取零拷贝 如果是ftp服务：利用transferTo实现零拷贝，这也是最正经的零拷贝概念，由DMA进行数据读取到内核，由内核发送到socket buffer，然后网卡传输出去]]></content>
      <categories>
        <category>NETTY</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>异步</tag>
        <tag>高性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HEXO安装教程]]></title>
    <url>%2F2018%2F12%2F11%2FHEXO%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[HEXO安装教程NEXT配置教程]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>HEXO</tag>
      </tags>
  </entry>
</search>
