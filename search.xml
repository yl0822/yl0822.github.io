<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[2019年度规划]]></title>
    <url>%2F2018%2F12%2F29%2F2019%E5%B9%B4%E5%BA%A6%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[工作 提升领域设计能力 提升需求缺陷识别能力 提升项目跟进并落地能力 提升外部沟通能力 提升时间安排能力 学习 阅读一本方法论相关的方面的书籍。 阅读一本领域驱动相关的方面的书籍。 精读一本操作系统相关的方面的书籍。 深化学习mysql和netty俩方面的内容。 持续维护个人博客，每个月输出不少于2篇技术博客。 生活 攒钱结婚 减肥，目标5-10KG 国/内外旅游各一次（重庆/菲律宾） 待定 待定]]></content>
      <categories>
        <category>规划</category>
      </categories>
      <tags>
        <tag>2019</tag>
        <tag>清单</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术basara（二）]]></title>
    <url>%2F2018%2F12%2F24%2F%E6%8A%80%E6%9C%AFbasara%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[java类加载器 三种 启动类加载器（bootstrapclassloader）：C++实现，无父类加载器，只加载JVM自身需要的类，包名为java、javax、sun等开头 扩展类加载器（extensionsclassloader）：java实现，父类加载器为null，加载JAVA_HOME/lib/ext目录下或者由系统变量-Djava.ext.dir指定位路径中的类库 应用类加载器（applicationclassloader）：java实现，父类加载器为ExtClassLoader，加载系统类路径java-classpath或-Djava.class.path下的类库 抽象类和接口 接口是规则的定制者，虽然接口也分层，多层次的接口组合形成了一组完整的规则，对该规则进行不同实现，完成面向对象的编程。 比如上帝，只创造生物这么一个概念，下层规则继续进行细化，比如微生物、动物、植物等，继续拆分动物包括卵生动物、胎生动物，继续拆分卵生动物包括消化系统、排泄系统、繁殖系统，以至于最终到玫瑰或者人这样一种完整的实现类。 比如大大，只传达房住不炒这么一个概念，下层住建部门进行规则细化，再下层省市级相关单位出台政策，最终到限购限售等等相关完整的实现类。 抽象类可以看做是一个半成品，它的抽象程度相对接口来说较低，但与其说抽象类是抽象，倒不如说抽象类是没想好或者无法完成定义在其中的abstract行为，从而交给子类。 常见到框架将两者结合起来，包括spring-ioc和netty，首先通过多层次的接口组合形成完备的规则，然后用抽象类对该套规则进行基本完备的实现，留下abs扩展点交予子类实现。 aop思想再理解 aop思想是oop的补充：极致的oop要求单个对象自行提供该对象的所有功能，但是某些行为一旦成为一种公用行为，那么oop思想导致了过多的代码冗余，维护和编写体验都非常糟糕，aop就是为了解决这种冗余存在的，将公用代码抽离形成切面，利用代理方式进行行为注入，解决上述问题。 关键点：代理 静态代理：在编译期间将切面注入到目标类中，也就是说classloader加载的是行为完备的类，这显然是需要在编译期进行一定处理的，aspectj框架实现了该套处理逻辑。 创建aj文件格式，通过ajc.exe命令进行编译，显然这个命令不是java自带命令，所以就需要进行环境变量的配置才能执行，配置后执行方式如：ajc -d . Hello.java TxAspect.aj 动态代理：方法区存储的依然是裸类，但是在运行期将切面行为注入，这里与其说是注入不如说是拦截，即先调用切面行为再调用实际方法，这种方式通过cglib和jdkproxy实现。]]></content>
      <categories>
        <category>basara</category>
      </categories>
      <tags>
        <tag>jdk</tag>
        <tag>classloader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊内存分配]]></title>
    <url>%2F2018%2F12%2F20%2F%E8%81%8A%E8%81%8A%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%2F</url>
    <content type="text"><![CDATA[内存是什么 内存是计算机最重要的硬件资源之一 其他硬件包括cpu、硬盘、显卡等、 有句话说程序=数据+算法，那么也可以说软件=内存+cpu 为什么还需要硬盘，因为内存是RAM，硬盘是ROM，两者区别在断电数据是否保存，如果你的软件不需要断电保存，就不需要硬盘，比如计算器功能，完全不需要ROM。 为什么还需要显卡，因为需要可视化，不管是计算机还是软件是给人用的，windows帮我们实现了os的可视化，我们也可以看到LOL客户端，所以需要显卡。 为什么还需要风扇，因为显卡、cpu运行发热需要降温否则被烧坏☺☺☺ 总之：内存是计算机的核心资源之一 内存是有限 依然如上所述：软件=内存+cpu，也就是说打开一个软件（进程），就需要消耗一定内存 尽管现代计算机的内存已经有4G、8G甚至更高，但是依然是有限的，而打开的程序是可以无限的，这里必然存在内存不足的痛点 资源有限，需求无限怎么办？答案：好刚在刀刃上 -&gt; 内存管理 进程和内存 不同进程间的内存是独立的，这里的不同进程包括本机和不同机器，也就是说本机打开一个PPT和一个WORD并不比两台机器各打开一个关系更亲密，当然考虑一下ROM的话还是要亲密一些的，因为ROM是进程共享的。 进程中的线程共享分配到的内存 一个例子简单说明描述OS的进程调度：比如，你正在厨房做饭，你一边看着菜谱一边按照菜谱将原料做成菜，就在这时，你儿子进来告诉你他擦破了腿，此时你停下手中的工作，将菜谱反扣过来，然后找来急救书按照书中的内容给你儿子贴上创口贴，贴完后你继续回去打开菜谱，然后继续做饭。在这个过程中，你就好比CPU，菜谱就好比程序，而做菜的原料就好比数据。你按照程序指令加工数据，而急救工作好比一个更高优先级的进程，中断了你当前做饭的工作,然后你将菜谱反扣过来（保护现场）,转而去处理高优先级的进程，处理完毕后你继续从刚才的页读菜谱(恢复现场)，然后继续执行做菜这个进程。 直接内存 早期计算机的进程直接访问内存，导致不同进程一旦操作相同的内存空间会导致两个进程一起崩溃，目前在单进程的操作系统可以采用这种方式，比如洗衣机、微波炉子类 现代计算机通过引入虚拟内存，允许进程拥有自己的内存地址，然后由寄存器进行实际物理内存地址计算，而每一个进程拥有的物理内存段不同 回到上述内存有限的问题上，开启过多进程后依然内存不足，为了应对这种情况，提出了内存交换（swap）技术，基本思想是将闲置的进程的内存暂存在ROM中，执行时再取回。在Java的堆外内存不足和Redis的内存不足时都采用了这种处理，但是这种方式带来的问题就是取回恢复的时候较慢，导致尤其是redis这种单线程进程阻塞，影响吞吐量。 内存碎片 分配给进程的内存要求连续，基于这个前提下，有下面一种事实： 内存分配给不同进程后，如果进程关闭，内存就空出，如果关闭掉的进程消耗的内存比较小，就无法分配给后续比其消耗内存大的进程，导致该快内存被一直空置，称为内存碎片，这种情况如果出现很多，显然就是一种浪费。为了应对这种情况，提出了内存压缩（compaction）技术，思路就是将多快小内存压缩成一块大内存，方式有很多，比如讲在线进程进行内存移动，将碎片内存填满，最终头部内存空出。再比如将所有在线进程复制到另外一块大内存，将原内存清空，然后从额外内存中重新加载进程。这两种不管哪种都会非常消耗CPU。 技术定位 malloc是学习C语言时碰到的函数 相生相伴的还有一个free方法 进程是持有内存资源的最小单位（线程是执行资源的最小单位） 核心关注点 分配效率 内存碎片 内存分配工具 ptmalloc glibc tcmalloc google jemalloc facebook]]></content>
      <categories>
        <category>basara</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[技术basara（一）]]></title>
    <url>%2F2018%2F12%2F20%2F%E6%8A%80%E6%9C%AFbasara%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[redis和mc对比 类加载 BootstrapClassLoader -&gt; ExtClassLoader -&gt; AppClassLoader -&gt; ConsumerClassLoader （jre系统类） （jre扩展类） （应用类） （自定义类） redis和mc 线程模型： reactor单线程：无锁提高效率，但是不能利用多核。 reactor多线程：索开销但是能利用多核 数据类型： 丰富：为了支持相应的数据结构，带来额外的cpu处理开销，再加上是单线程，导致某些操作会极大影响系吞吐量如：keys kv：数据结构支持简单 内存分配： 临时申请 ：Redis使用现场申请内存的方式来存储数据，并且很少使用free-list等方式来优化内存分配，会在一定程度上存在内存碎片 预分配：将申请下来的内存空间按成长梯度划分为多个slab，slab内部又划分为大小相同的chunk，分配过程中查找适合的chunk进行处理，好处：规避内存分配开销，缺点：空间存在一定浪费。 淘汰策略： redis：延迟淘汰 + 定期淘汰 mc：延迟淘汰 分布式支持 cluster：通过去中心化，将所有key分散在16000+个slot上（CRC16(key)%slot_size），每个节点均分slot数量，并提供主从冗余和故障转移机制，保证cluster模式下高可用，在扩容的场景下，也能通过进行slot匀分进行重新数据再分配。 客户端：mc本身不支持分布式，只能通过在客户端通过分片算法进行多节点部署后的伪分布式。 redis的swap机制 并不是所有kv都存放在内存，而是k是一定存在内存，但是v有可能因为长时间冷却后被存放在磁盘，触发时机是在内存使用量达到一定阈值，这些数据会放在swap文件中。 但是如果从swap中获取数据，会导致额外的IO开销，从而增加主线程的阻塞时间。 zookeeper的watcher机制 能力：提供分布式环境的下发布/订阅功能、通知等功能 客户端（jar）在向服务端注册Watcher的同时，会将该对象添加到WatcherManager对象中。 当ZooKeeper 服务器触发 Watcher 事件后，会向客户端发送通知，客户端线程从 WatchManager 的实现类中取出对应的 Watcher 对象来执行回调逻辑。 zk的集群方式和redis的cluster集群方式看起来似乎一样，但是为什么两者的HA和扩缩容方式不一样呢 HA zk的HA原则是，只要集群中的节点还存在半数以上存活，就能提供完整的服务，也就是说如果要部署一个容错度为N（比如说N就是服务器的数量）的zk集群，那么部署2N+1台服务器构集群即可（偶数台机器只能提供和偶数台 - 1数量的集群一样的容错度，故不推荐使用）， redis的HA是通过传统的主从方式实现的， 扩缩容 zk的扩缩容没有经常听到，是因为zk并不是cpu敏感（hadoop）、磁盘敏感（DB）、内存敏感（redis）的中间件，只要初期经过容量评估基本是不需要扩容的，如果需要扩容 整体重启：简单、服务不可用（zk一般在服务中不是属于强关联组件，比如dubbo、配置中心等，而且重启时间虽然连接断开，但是不计入session失效时间，所以允许短暂时间的可用就可以使用这种方式） 逐台重启：适合大多数场景，保证服务可用。 redis而扩缩容是通过对部分slot进行重新分配实现的，这里需要注意服务器挂掉和缩容的区别在于后者是经过内存考量后的处理，且进行过了数据迁移，而挂掉则不是。 HA包含多方面的问题，至少有以下两方面考量： 单点问题：冗余 + 故障转移 容灾考量：指火山、地震、海啸、战争等情况下，就算你提供了N台服务器的容错度，但是你TM整个机房都没有了，如何保证服务的HA（企业：这TM不扯淡吗），在高价值的企业服务和数据的场景下，这些事有必要的，比如银行存款数据，比如支付宝数据，如果一个地震好死不死把支付宝大楼震倒了（假设支付宝的机房都在这栋大楼里），那全国人民支付宝里面的钱都没有了（用户：这TM不扯淡吗），因为企业依赖于用于，所以企业需要思考这种问题，所以有了多机房的方案。这理论上也是机房出现了单点问题，其实这个概念再延伸，对公司来说个体是冗余+失备援（故障转移）的也就是你在你辞职了公司可以随时再招聘一个，但是每个个体也就是对我们每个人来说我们都有单点问题，再大点，整个人类都存在单点问题：地球。 双机房：就zk的2N+1理论，不管怎么部署都不能保证某个机房挂掉后的可用性 三机房：解决上面的问题，但是tm贵啊！ rpc和resetful rpc 代表alibaba-dubbo、apache-thrift 优点：自定义通信协议，这就意味着可话最少的空间传输最多的信息，节省带宽（80%），采用TCP长连接减少握手，性能高。 缺点：因为要保持长连接所以需要接入客户端，另外需要感知客户端的调用方式变化（比如pom的包升级）。 restfule 代表spring-cloud 优点：能穿透防火墙（默认80才能通过），专注服务端提供服务并对外传输数据，完全不用考虑调用方。 缺点：扩缩容需要修改nginx，而rpc只需要通过zk动态感知即可。 业内对微服务的实现，基本是确定一个组织边界，在该边界内，使用RPC; 边界外，使用Restful。这个边界，可以是业务、部门，甚至是全公司。（也就是说内网通信用RPC，外网通信用HTTP） 接续上述，另外一个区别角度是异构系统（不同系统不同语言）用http，相同语言用RPC 接续上述，一般rpc都会提供泛化调用的能力，一定程度上兼容异构系统]]></content>
      <categories>
        <category>basara</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>memcache</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty学习笔记]]></title>
    <url>%2F2018%2F12%2F17%2FNetty%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基础篇 见前篇：NIO知识拾取 接口体系领域对象接口Channel ChannelGroup：维护多个Channel并提供各种批量操作，关闭的Channel会被自动移除，用于将多个Channel进行业务分组 ChannelPipeline -&gt; DefaultChannelPipeline 持有head和tail两个ChannelHandlerContext作为入口节点 持有绑定的Channel 持有是否有绑定Channel ChannelPipeline#fireChannelReadComplete默认传入 ChannelHandler 用于用户进行功能扩展 ConsumerRpcClientHandler -&gt; ChannelInboundHandlerAdapter ConsumerRpcServerHandler -&gt; SimpleChannelInboundHandler -&gt; ChannelInboundHandlerAdapter 用于IO行为处理，具体分为3类： 不做任何跳转行为 12345public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; Channel incoming = ctx.channel(); logger.info(&quot;Socket客户端：[&quot; + incoming.remoteAddress() + &quot;] 建立连接成功.&quot;); channelGroup.add(ctx.channel()); &#125; 同类事件行为跳转 1234567891011public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; numReads = 0; discardSomeReadBytes(); if (decodeWasNull) &#123; decodeWasNull = false; if (!ctx.channel().config().isAutoRead()) &#123; ctx.read(); &#125; &#125; ctx.fireChannelReadComplete(); &#125; 不同事件行为跳转 123public void channelReadComplete(ChannelHandlerContext ctx) &#123; ctx.flush(); &#125; ChannelHandlerContext -&gt; AbstractChannelHandlerContext 属性描述 持有next和prev两个ChannelHandlerContext作为双向链接 持有所属ChannelPipeline对象 持有布尔类型的inbound和outbound属性 持有节点状态：初始化 -&gt; 待添加 -&gt; 已添加 -&gt; 已移除（） （可能）持有自己的业务线程EventExecutor，如果没有默认使用NIO线程 如果配置了业务线程，那么将某些事件的处理逻辑封装为task交给业务线程处理，事件包括不限于（但是以下事件做了缓存）： invokeChannelReadCompleteTask：读取完成事件 invokeReadTask：读取事件 invokeChannelWritableStateChangedTask：写状态变更事件 invokeFlushTask：写数据发出事件 行为描述 传递行为，如红框所示：ChannelInboundHandler#channelRead 传递行为，如红框所示：ChannelOutboundHandler#read 核心行为一：ChannelHandlerContext#invokeChannelReadComplete(ChannelHandlerContext next) 获取EventExecutor 判断EventExecutor是否是NIO线程 如果直接调用next的ChannelInboundHandler#channelReadComplete ChannelInboundHandlerChannelOutboundHandler领域行为接口NioEventLoop其他ReferenceCounted 被引用计数包含的对象，能够显示的被垃圾回收。当初始化的时候，计数为1。retain（）方法能够增加计数，release() 方法能够减少计数，如果计数被减少到0则对象会被显示回收，再次访问被回收的这些对象将会抛出异常。如果一个对象实现了ReferenceCounted，并且包含有其他对象也实现来ReferenceCounted，当这个对象计数为0被回收的时候，所包含的对象同样会通过release()释放掉。 实际云音乐的RPC-DEBUG客户端调用链路Channel.writeAndFlush -&gt; io.netty.channel.AbstractChannel#writeAndFlush(java.lang.Object, io.netty.channel.ChannelPromise) || \/ChannelPipeline.writeAndFlush -&gt; io.netty.channel.DefaultChannelPipeline#writeAndFlush(java.lang.Object, io.netty.channel.ChannelPromise) || \/ChannelHandlerContext.writeAndFlush -&gt; io.netty.channel.AbstractChannelHandlerContext#writeAndFlush(java.lang.Object, io.netty.channel.ChannelPromise) || \/ChannelHandlerContext.writeAndFlush -&gt; io.netty.channel.AbstractChannelHandlerContext#writeAndFlush(java.lang.Object, io.netty.channel.ChannelPromise) || \/Channel.writeAndFlush -&gt; io.netty.channel.AbstractChannel.AbstractUnsafe#write || \/Channel#flush -&gt; io.netty.channel.AbstractChannel.AbstractUnsafe#flush || \/NioSocketChannel#flush -&gt; io.netty.channel.socket.nio.NioSocketChannel#doWrite || \/SocketChannel#write -&gt; sun.nio.ch.SocketChannelImpl#write(java.nio.ByteBuffer) 服务端调用链路NioEventLoop#processSelectedKeysOptimized || \/AbstractNioByteChannel.NioByteUnsafe#read || \/DefaultChannelPipeline#fireChannelReadComplete || (HeadContext) || \/AbstractChannelHandlerContext#invokeChannelReadComplete || \/ChannelInboundHandler#channelReadCompleteio.netty.handler.codec.ByteToMessageDecoder#channelReadCompleteio.netty.channel.ChannelHandlerContext#fireChannelReadComplete]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>异步</tag>
        <tag>高性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql学习笔记]]></title>
    <url>%2F2018%2F12%2F15%2FMysql%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[结构 连接池组件 管理服务和工具组件 SQL接口组件 查询优化器组件 优化器组件 缓存组件 插件式存储引擎（是mysql区别于其他db的重要特性，不同引擎有不同特点，开发者可以根据引擎接口编写主键的存储引擎或者修改已有引擎的源码来实现自己的需求） 物理文件 InnoDB基础 划重点：很多人用 基本介绍 支持事务（OLTP（联机事务处理过程）应用常见需求） 支持行锁（提高单表并发能力） 支持MVCC（实现读写并发和基于该特性实现的隔离级别） 支持外键（分布式部署下不建议使用） 高级功能 插入缓冲 二次写：doubl ewrite：看不懂，应该是个保障服务器宕机后的数据一致性机制，skip it！ 自适应哈希索引 哈希查找很快O(1) innodb是否建立hash表由系统决定，不能人为干预，所以叫自适应 通过buffer_pool的B+树构造，且按需建立，所以建立速度很快 提高读写数据（聚集索引提升2倍，普通索引5倍） 预读 其他描述 表空间：ibd文件，由InnoDB管理 聚集索引：表的存储按聚集索引的顺序存放 使用 TCP方式：mysql -h 192.168.0.1 -u root -p root mysql通过持有一张权限表来判断TCP权限：user表 InnoDB体系架构模型 拥有多个内存块 -&gt; 内存池，负责： 维护所有mysql线程/进程需要访问的数据资源 缓存磁盘数据，方便快速读取，缓冲写操作，并通过后续的脏页刷盘达到顺序写的效果提高效率 存储各种过日志：redo、undo、slow、query buffer pool redo log buffer additional memory pool 后台线程，负责： 根据LRU原则从磁盘读取并刷新内存池数据 将写数据刷新到磁盘保证ACID特性 7个线程： 4个IO线程(可配置，默认4) insert buffer thread log thread read thread write thread 1个master线程 1个锁监控线程 1个错误监控线程 工作方式 以页(16K)为单位将数据从磁盘读取到buffer pool，线程按LRU算法操作 写操作时，先修改在缓冲池中的页并将操作日志存放到redolog中进行持久化，成为脏页后按一定的频率进行刷盘，如果脏页刷盘失败如服务器挂掉，则重启后从redolog进行恢复 内存构成详细 buffer pool innodb_buffer_pool_size指定缓冲池大小 show engine innodb status查看buffer pool的使用情况 buffer pool size：总大小 free buffers：可用大小 database pages：已用大小 modified db pages：脏页大小 存放内容 索引页（核心） 数据页（核心） undo页 插入缓冲：在单条记录插入时， 聚集索引插入顺序读取，无效率问题 普通索引无顺序，且可能会有多个，插入效率降低（B+树的特性） 判断普通索引页是否在缓冲区，如果在直接更新，如果不在存放在插入缓冲区，通过master thread进行merge操作，这样可以将多个普通索引插入操作合并到一个merge操作中，大大提高普通索引的插入和修改性能，某种意义上也是脏页的一种，所以如果考虑服务器宕机的情况，就会需要很长时间的恢复操作。引申一点：在单机环境下总是要考虑服务器是不可靠的是会宕机的，而在分布式环境下，除了要考虑单机宕机还要考虑网络传输是不可靠的，甚至是不安全的（信息截取），从这两个方面引申出来的就是目前互联网上各种系统、中间件如此复杂的最大原因之一，比如：单点问题、高可用、主从、CAP、分布式事务、一致性协议、HTTPS等等 自适应hash索引 锁信息 数据字典 从上述可以看到没有redolog，那么放哪里呢？ 日志缓冲log_buffer：用于redolog缓冲，落盘到redolog之后可以重用，所以无需设置太大 额外内存：理解为用于管理buffer pool的一些元数据 线程详解 master thread核心工作线程 小循环操作（每秒） 脏页刷盘 redolog日志刷盘（由于write_ahead机制log_buffer中的数据从事务开始就写，但是即使事务没有提交，也会进行这一步的刷盘操作，提高大事务的commit效率） 合并插入缓冲（将多条写语句merge为一条） 大循环操作（每10秒） 除了上述三个动作也会做，还负责： 删除undo页（在MVCC机制下，只要当undo的数据版本没有在任何一个事务中作为快照返回才能进行删除操作） 生成checkpoint 高并发下的缺点 没有跟上硬件（SSD）的发展速度导致它这种模式慢 文件 分类如下： 参数文件 kv结构，保存mysql所有配置数据 show varables like &#39;%%&#39;查看全部数据 日志文件 errorlog（用于dba错误排查） slowlog（用于sql优化） querylog（好像没什么卵用） binlog（记录所有写操作，用于本机恢复和replica同步） socket文件 pid文件 表结构文件（mysql系统对表结构信息的存储） 存储引擎文件（innodb对表结构信息的存储） 表空间文件（存储表数据） 重做日志文件： 存在多份，记录事务日志，空间可以复用，脏页刷盘后可以被覆写。 作用是如果服务器挂掉，服务器重启会读取redolog进行事务数据恢复保证ACID特性不被破坏。 和binlog的区别： binlog记录mysql所有引擎的动作 binlog记录事务具体操作，redolog记录页的变更情况（这里和脏页建立关联，从而配合第一条的刷盘覆写） binlog再事务提交前才进行记录，redolog在事务开始过程中不断写入（当然考虑日志缓冲，但是配合master thread的未提交刷盘动作，说是不断写入也是正确的）顺便说下binlog的三种记录模式：row-&gt;记录每一行的修改操作，statement-&gt;记录每一条修改操作，mix-&gt;根据结果选择上述其中一种，比如删全表100条，row模式记录100条日志，statement记录一条即可，mix的选择判断来源于expain的rows信息 表 数据的存放和组织组成结构：tablespace -&gt; segment -&gt; extent -&gt; page -&gt; row tablespace，存放内容如下：（其他信息存放在共享表空间，和额外内存的关系???） 数据 索引 插入缓冲 segment： 数据段：innodb数据由聚集索引组织，所以数据段就是B+树的叶子节点 索引段：B+树的非叶子节点 回滚段 extent：连续64个页组成 page：innodb磁盘管理的最小单位，16K 根据存放内容划分的不同页类型： 数据页 undo页 系统页 事务数据页 插入缓冲位图页 插入缓冲空闲列表页 未压缩的二进制大对象页 压缩的二进制大对象页 页的存放结构 file header 页所属空间 表空间页的偏移量 上下页引用（B+树的叶节点的双向关联） 页最后修改的LSN（log sequence number） 页类型 page header infimun + supremum records user records free space page directory file trailer感觉和java的对象结构和类结构很像，顺便回忆一下java对象结构：Object header(markword(hashcode + gc age + flag + lock status) + klass pointer + array size)+ object body + padding，类结构：cafe babe + sub version + main version + constants pool size + constant pool + access flag + field + method + code + … row：innodb存放数据的单位，每一页最多存储8千行 skip数据完整性约束部分，因为分布式数据库一般禁止使用外键、视图、存储过程，甚至唯一键都希望能在程序中进行保证而不是通过数据库。 skip分区表，不知道是什么鬼（在学习知识的过程中，进行信息筛选也是非常重要的） 索引 lielaliela终于来了~ 概述 索引用于提高查询效率，但是减低写效率，是一种均衡的考虑。tip：所有技术选型其实都是折衷和均衡的艺术 查询算法三板斧 哈希：O(1)，可惜不支持顺序，但是使用DB的应用顺序查询是非常重要的脱离实际业务的技术都是耍流氓，所以mysql很少用到哈希，唯一用到地方就是上述的自适应哈希索引。 顺序：O(n)，属于鸡肋，弃之。 二叉树：O(logn)，属于顺序和查询皆可的方式，原生二叉树查找在DB大数据量的层面下显得太书生气，一个是树高太高导致IO次数太多，一个是节点存储数据太少，导致无法利用磁盘预读，于是进行改造后形成B+树，每个非叶子节点存储一页数据（16K），比如一个自增主键索引用16位的long类型，那么能存储1000个子节点，子节点同理，也就是到第三阶，就能存储几亿级别的数据量，另外B+树叶子节点之间通过双向连接，在顺序查询的效率上更加高效。另外根据上述的索引构成，B+树索引并不能找到具体数据所在行，而只能找到行所在页，所以mysql通过将页读入内存再进行查找才能得到数据。 一般来说，应用的数据的表都不会多的离谱，所以一般2-3阶B+树就能满足所有的需求，也就是IO2-3尺就能拿到数据所在的页，根据普通SATA盘的寻道时间10ms左右，所以20-30ms就能查到数据相应数据，当然具体来说需要根据使用的索引类型和查询范围来确定。 聚集索引 如上述所言，innodb通过聚集索引的顺序来进行数据存储，那么以聚集索引构建的B+树的叶子节点也就是实际磁盘中的数据存储顺序，实际上其实就是这样：聚集索引的叶子节点直接存储行数据，这个特性决定了： 数据是索引的一部分 只能以一颗B+树顺序进行构建，所以只能有一个聚集索引 普通索引的叶子节点存放聚集索引的值，然后通过二次查找进行数据获取 因为能在叶子节点上直接找到数据，所以通过聚集索引查询效率更高这里有个例外情况：如果我们查找的数据就是聚集索引所在的字段，那么通过普通查询获取到了聚集索引之后就无需进行二次查找，直接返回，再考虑到行数据所占空间肯定比聚集索引字段占用空间大，于是单位页下后者能存储的数据量更多，所以定位的速度更快，这就是覆盖索引的原理 聚集索引决定了数据的存储顺序，这里要注意的是并不是物理顺序，而是逻辑顺序，因为如果是物理顺序，由于行数据所占空间大小的不确定性，要维护这个物理顺序是非常困难的，实际它是通过在页间用双向链表，页内也是双向链表的方式进行数据组织。 非聚集索引：也叫二级索引、普通索引、辅助索引 不决定数据顺序，所以可以有多个普通索引 也是由于不决定数据顺序，所以进行的是随机读，确实导致读取效率是偏低的，但是通过预读和缓冲区等技术减低了相应成本。 联合索引 联合索引也只建立一颗B+树 根据索引组合的顺序如a+b+c建立，整体视角下，a是有序的，在a确定之后，b才是有序的，而整体视图下b本身是无序的，如果后面还有依次类推，于是有下面机制 头部匹配 配合sql索引优化器，如果建立了abc联合索引，那么所有组合： a（可以） b（不可以） c（不可以） ab（可以） ba（可以） ac（可以） ca（可以） bc（不可以） cb（不可以） abc（可以） acb（可以） bac（可以） bca（可以） cab（可以） cba（可以） 索引管理 索引的增删：创建新表（新索引） -&gt; 导入数据 -&gt; 删除原表 -&gt;命名新表为原表 快速创建方式：只针对普通索引，聚集索引还是按上述方式处理：表加上读锁 -&gt; 更新内部视图 -&gt; 标记普通索引空间为可用 -&gt; 删除视图上的定义。 show index from table查看索引信息，其中有个关键信息：cardinality(区分度)（distinct(index_field)/table_count）用于描述该索引下区分度，也就是说cardinality=1意味着唯一索引，如果很小，就应该是否应该建立索引。该值是并不会在实时更新，是一个概值，用于索引优化器进行判断是否需要走索引或者是走扫描方式。 什么时候考虑建普通索引： 高区分度（无区分度比如不建,比如boolean值建索引） 少量获取（虽然区分度高但是大量获取，比如获取time &lt; now） 针对上面两种情况，我们是不建议建索引吗，但是即便你建立了索引，优化器也可能不会走 其他概念了解 顺序读：虽然上面提高聚集索引的数据也只是逻辑顺序并不是磁盘顺序，本质上也是随机读，但是从整体上来看是存在一定顺序，比如在区上是连续的64个页。 随机读：需要磁头不断移动，SATA盘瓶颈正是在于寻址时间长，所以效率低（SSD如何?）。 预读：一次IO请求获取多个页数据放在buffer pool，这种机制下，聚集索引就更有优势，有可能一次IO就能完成数据查找，而对随机读来说，获取的数据量越多，数据可能存在的概率也越大，减少随机读的次数的概率也越大。 锁 如上所述，所有架构选型都是均衡的艺术：数据库的选型就是性能（并发）和一致性的均衡。保证一致性的方式：锁 DB区分于文件系统的特性 完整性约束 锁 事务 innodb的锁 共享锁：读读并发，读写互斥，写写互斥 独占锁：独占！ 意向锁：表级别的锁，目的是为了在事务中揭示下一行要被请求的锁的类型（看不懂(┬＿┬)） 三张表 innodb_trx 事务ID 当前事务状态 事务开始时间（可以用于快照的版本确定） 等待目标事务的锁ID，配合事务状态为lock wait 事务等待开始时间 事务权重（死锁时权重最小的回滚） 线程ID 事务运行的sql innodb_locks 锁ID 事务ID 锁模式 锁类型（表锁/行锁） 锁住的表 锁住的索引（通过锁住聚集索引实现的行锁） 表空间ID 锁住的页数量（行锁才有意义） 锁住的行数量（行锁才有意义） 锁住的行的主键值（多行如何设置?） innodb_waits 申请锁资源的事务ID 申请的锁ID 阻塞的事务ID 阻塞的锁ID 快照读 通过MVCC的思想实现读写并发（共享锁的并发能力还不够），通过读取快照版本数据实现快照版本通过undo实现，但与其说是undo实现，倒不如说是innodb的undo机制正好用于实现快照，从而可以在不带来额外成本的情况下实现MVCC机制 在不同事务隔离级别下的不同表现 RC：读取最新快照信息 RR：读取开始时的最老快照信息，需要注意事务开始时间和数据读取时间不一样，而这里的开始时间指的是后者 innodb的select操作默认都是快照读，同时也支持读加锁（当前读） select … for update：所读记录加X锁，但是依然能被快照读 select … lock in share mode：所读记录加S锁，显然能被快照读 上述两种读取方式需要在事务中，当事务结束释放锁（类似于Lock） 其他锁 自增主键锁：表锁 外键和锁：skip！ 锁算法 record lock：行锁 gap lock：间隙锁 next-key lcok：临键锁 = record lock + gap lock select where id &lt; 6 lock in share mode：那么insert id=3阻塞，insert id=10成功 锁解决事务带来的问题 更新丢失：两个事务同时读取并根据记录值进行修改操作，用户有100块钱，T1事务读取到100，T2也读取到100，两者同时花钱100得到-100，如果有非负约束得到0，而用户花出去200，则显然是错误的，处理方法：串行执行（加锁）。 脏读：事务a读取到事务b未提交的数据，违反隔离性原则。RC级别下就可以解决，方式是：快照读，因为快照读的版本是通过undo段实现的，如果事务未提交，undo段会回滚并删除。 不可重复读：一个事务两次读取数据不一致，这里的数据分两种，一个单条数据被update后的不一致，一个是数据被insert或者delete带来的不一致，一般来说前者叫不可重复读，由RR级别解决，后者叫幻读由Serialize级别解决，但是innodb环境下，两者都称为不可重复读，所以RR就需要将两者全部解决，方式是：通过最旧快照读 + 临键锁解决，最旧快照读保证update不可见，临键锁保证插入和删除阻塞。 阻塞 一个事务中需要等待另外一个事务中的锁释放，通过posix thread模型中的mutex_enter函数实现，释放由mutex_exit实现，这里考虑synchronized的monitor_enter和moniter_exit是一样的实现。 死锁：拉到最上面的线程那块，介绍了多种线程，其中有一种就是锁监控线程，负责查看死锁问题并告知用户，大部分情况下，数据库可以自己解决死锁：通过事务回滚即可（还记得上面的事务权重吗） 事务 事务的ACID特性 如何保证已提交事务的ACID log_buffer + redolog实现 事务开始时就写log_buffer并记录LSN 事务提交时将log_buffer的记录写入redo（未提交也写入，见master thread部分） redolog落盘 上述两步称为wrtie-ahead logging机制 如何保证未提交事务的ACID undo段 事务开始时写入undo 存放在共享表空间的特殊segment中（redo放在文件redolog中） 存放内存： 对于insert，存放insert记录的ID（回滚时直接根据ID记性delete） 对于delete，存放整条原记录（回滚时直接insert） 对于update，存放整条原记录（回滚时直接udpate） 总结 整片下来花了五个小时，基本是对之前innodb相关知识的回顾和串联，当然也理清了一些思路，收货很大，书如下：]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>InnoDB</tag>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NIO知识拾取]]></title>
    <url>%2F2018%2F12%2F14%2FNIO%E7%9F%A5%E8%AF%86%E6%8B%BE%E5%8F%96%2F</url>
    <content type="text"><![CDATA[IO基础BIO 没有缓冲区，通过InputStream/OutputStream直接从用户空间到内核空间（为什么这样效率很低?） 同步阻塞IO，导致线程也被阻塞 NIOBuffer- 是一块可写入和读取的内存块，包装后提供了一组方法进行内存块的操作和访问 - 基本用法 - capacity：缓冲区总容量 - position：游标位置（写操作下，游标和limit一样一直增加，rewind时，游标复位，limit不变，flip时，游标复位并将limit设置成之前position的值） - limit：缓冲区已用大小 - flip()：- 当向buffer写入数据时，buffer会记录下写了多少数据。一旦要读取数据需要通过flip()方法将Buffer从写模式切换到读模式。在读模式下，可以读取之前写入到buffer的所有数据。 - clear()：一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。有两种方式能清空缓冲区：调用clear()或compact()方法。clear()方法会清空整个缓冲区。compact()方法只会清除已经读过的数据 12345678910111213RandomAccessFile aFile = new RandomAccessFile(&quot;nio-data.txt&quot;, &quot;rw&quot;);FileChannel inChannel = aFile.getChannel();ByteBuffer buf = ByteBuffer.allocate(48); // 生成48字节大小的缓冲区int bytesRead = inChannel.read(buf); // 读取数据到缓冲区while (bytesRead != -1) &#123; buf.flip(); // 准备从缓冲区读取数据 while(buf.hasRemaining())&#123; System.out.print((char) buf.get()); // 每次读取1个字节 &#125; buf.clear(); // 清空用于再次读取 bytesRead = inChannel.read(buf);&#125;aFile.close(); - 关于HeapByteBuffer和DirectByteBuffer的几个疑问释疑 - DirectByteBuffer是否是内核空间? - DirectByteBuffer毫无疑问属于堆外内存，但是依然属于操作系统体系中的用户空间，它通过glibc的ptmalloc函数分配的内存。 - DirectByteBuffer为什么能提高效率? - DirectByteBuffer能减少一次拷贝,也就是说即使直接用HeapByteBuffer进行IO的时候也会默认创建一个DirectByteBuffer进行中转 - 为什么HeapByteBuffer不能直接写到内核空间而需要先拷贝到DirectByteBuffer再到内核空间? - 因为内核空间的ReadFile（[FileInputStream与FileChannel对比](https://blog.csdn.net/infant09/article/details/80044868) ）方法要求必须连续的内存，且使用期间该内存不得被操作。 - 而在jvm-heap上这两点都不能满足 - HeapByteBuffer分配出来的内存块处于jvm-heap上，在GC后（带有整理过程的算法如CMS），内存地址会改变 - HeapByteBuffer持有的byte[]数组在jvm规范下并不要求内存连续 - 而c-heap都能满足 - GC管不着，由操作系统进行内存空间管理 - glibc.ptmalloc分配的内存保证连续 - 能直接对DirectByteBuffer进行业务操作吗? - 不能，如果需要对数据进行业务操作（编解码、解析、过滤），还是需要拷贝的jvm-heap。 - 综上所述：和我之前想法也是一致的，与其说DirectByteBuffer节省了内存拷贝，倒不如说是因为HeapByteBuffer要多一次拷贝，所以DirectByteBuffer要快一些。 - 所以netty使用堆外内存进行优化是这样的： - 如果是用于RPC服务开发：利用堆外内存实现数据发送时的零拷贝，另外通过CompositeByteBuf的bytep[]组装功能实现零拷贝 - 如果是用于服务转接开发：利用堆外内存实现读取零拷贝 - 如果是ftp服务：利用transferTo实现零拷贝，这也是最正经的零拷贝概念，由DMA进行数据读取到内核，由内核发送到socket buffer，然后网卡传输出去 Channel]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>异步</tag>
        <tag>高性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HEXO安装教程]]></title>
    <url>%2F2018%2F12%2F11%2FHEXO%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[HEXO安装教程NEXT配置教程]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>HEXO</tag>
      </tags>
  </entry>
</search>
